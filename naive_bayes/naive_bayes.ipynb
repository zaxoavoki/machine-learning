{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600295940905",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Pros:\n",
    "\n",
    " - It is easy and fast to predict class of test data set. It also perform well in multi class prediction.\n",
    "\n",
    "Cons:\n",
    "\n",
    " - If categorical variable has a category (in test data set), which was not observed in training data set, then model will assign a 0 (zero) probability and will be unable to make a prediction. \n",
    " - Limitation of Naive Bayes is the assumption of independent predictors. In real life, it is almost impossible that we get a set of predictors which are completely independent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "Implement the main part of algorithm.\n",
    "\n",
    "In our example we have four features x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, x<sub>4</sub> as sepal length, sepal width and etc. We have only 3 classes to predict: Iris-setosa, Iris-versicolor and Iris-virginica. To find a class to which flower belongs we need to count predictions in this way: \n",
    "\n",
    " - for each class count it's prediction `P(Y|all)` what means to divide number of classes `Iris-setosa` in all dataset (50 / 150).  \n",
    "\n",
    " - then for each feature divide the number of the same features in the dataset by number of all classes `Iris-setosa`.  \n",
    "\n",
    " - multiply all result and find the max value.\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 93.33333333333333%\n"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/iris.csv', header=None)\n",
    "\n",
    "tests = df.sample(15)\n",
    "train = df.drop(tests.index)\n",
    "\n",
    "err = 0\n",
    "for test in np.array(tests):\n",
    "    best = []\n",
    "\n",
    "    for _class in train.iloc[:, 4].unique():\n",
    "        class_count = train.loc[train[4] == _class].count()[0]\n",
    "        pred = class_count / train.shape[0]\n",
    "        \n",
    "        for col, x in enumerate(test[:4]):\n",
    "            class_feature_count = train.loc[(train[col] == test[col]) & (train[4] == _class)].count(axis=0)[0] + 1\n",
    "            pred *= class_feature_count / class_count\n",
    "\n",
    "        best.append((pred, _class))\n",
    "    best = max(best, key=lambda x: x[0])\n",
    "    err += 1 if best[1] != test[4] else 0\n",
    "\n",
    "print(f'Accuracy: {(1 - err / tests.shape[0]) * 100}%')"
   ]
  }
 ]
}